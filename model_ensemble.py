"""
Model Ensemble System
---------------------
‡∏£‡∏ß‡∏°‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥

Supported Models:
- XGBoost
- Random Forest (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
- LightGBM (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)

Ensemble Methods:
- Voting (Majority Vote)
- Weighted Average
- Stacking

‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:
    python model_ensemble.py --data-path data/price_with_sentiment.csv
"""

import argparse
import pickle
from pathlib import Path

import joblib
import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    f1_score,
    precision_score,
    recall_score,
    roc_auc_score,
)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

try:
    import lightgbm as lgb

    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("‚ö†Ô∏è LightGBM not available. Using XGBoost and RandomForest only.")


class ModelEnsemble:
    """
    Ensemble ‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
    """

    def __init__(self, ensemble_method="voting"):
        """
        Initialize Ensemble

        Args:
            ensemble_method: 'voting', 'weighted', or 'stacking'
        """
        self.ensemble_method = ensemble_method
        self.models = {}
        self.ensemble = None
        self.scaler = StandardScaler()
        self.feature_names = None

    def create_models(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        print("\nü§ñ Creating individual models...")

        # 1. XGBoost
        print("  1. XGBoost...")
        self.models["xgboost"] = xgb.XGBClassifier(
            max_depth=5,
            learning_rate=0.05,
            n_estimators=200,
            objective="binary:logistic",
            eval_metric="logloss",
            use_label_encoder=False,
            random_state=42,
        )

        # 2. Random Forest
        print("  2. Random Forest...")
        self.models["random_forest"] = RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1,
        )

        # 3. LightGBM (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        if LIGHTGBM_AVAILABLE:
            print("  3. LightGBM...")
            self.models["lightgbm"] = lgb.LGBMClassifier(
                num_leaves=31, learning_rate=0.05, n_estimators=200, random_state=42
            )

        print(f"\n‚úÖ Created {len(self.models)} models")

        return self.models

    def train_individual_models(self, X_train, y_train, X_val, y_val):
        """‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß"""
        print("\n" + "=" * 70)
        print("TRAINING INDIVIDUAL MODELS")
        print("=" * 70)

        results = {}

        for name, model in self.models.items():
            print(f"\nüîß Training {name.upper()}...")

            try:
                # Train
                model.fit(X_train, y_train)

                # Evaluate
                y_pred = model.predict(X_val)
                y_proba = (
                    model.predict_proba(X_val)[:, 1]
                    if hasattr(model, "predict_proba")
                    else y_pred
                )

                accuracy = accuracy_score(y_val, y_pred)
                precision = precision_score(y_val, y_pred)
                recall = recall_score(y_val, y_pred)
                f1 = f1_score(y_val, y_pred)
                auc = roc_auc_score(y_val, y_proba)

                results[name] = {
                    "accuracy": accuracy,
                    "precision": precision,
                    "recall": recall,
                    "f1": f1,
                    "auc": auc,
                }

                print(f"  Accuracy:  {accuracy:.4f}")
                print(f"  Precision: {precision:.4f}")
                print(f"  Recall:    {recall:.4f}")
                print(f"  F1-Score:  {f1:.4f}")
                print(f"  AUC-ROC:   {auc:.4f}")

            except Exception as e:
                print(f"  ‚ùå Error training {name}: {e}")
                continue

        return results

    def create_voting_ensemble(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Voting Ensemble"""
        print("\nüó≥Ô∏è Creating Voting Ensemble...")

        estimators = [(name, model) for name, model in self.models.items()]

        self.ensemble = VotingClassifier(
            estimators=estimators,
            voting="soft",  # soft voting (use probabilities)
            n_jobs=-1,
        )

        print(f"‚úÖ Voting Ensemble created with {len(estimators)} models")

        return self.ensemble

    def create_weighted_ensemble(self, weights=None):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Weighted Ensemble"""
        print("\n‚öñÔ∏è Creating Weighted Ensemble...")

        if weights is None:
            # Default: ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
            weights = [1.0 / len(self.models)] * len(self.models)

        estimators = [(name, model) for name, model in self.models.items()]

        self.ensemble = VotingClassifier(
            estimators=estimators, voting="soft", weights=weights, n_jobs=-1
        )

        print(f"‚úÖ Weighted Ensemble created")
        print(f"   Weights: {dict(zip(self.models.keys(), weights))}")

        return self.ensemble

    def train_ensemble(self, X_train, y_train):
        """‡πÄ‡∏ó‡∏£‡∏ô Ensemble"""
        print("\n" + "=" * 70)
        print(f"TRAINING ENSEMBLE ({self.ensemble_method.upper()})")
        print("=" * 70)

        if self.ensemble_method == "voting":
            self.create_voting_ensemble()
        elif self.ensemble_method == "weighted":
            # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å F1-score ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
            # (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å validation set)
            self.create_weighted_ensemble()

        print("\nüîß Training ensemble...")
        self.ensemble.fit(X_train, y_train)
        print("‚úÖ Ensemble training complete")

        return self.ensemble

    def evaluate_ensemble(self, X_test, y_test):
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Ensemble"""
        print("\n" + "=" * 70)
        print("ENSEMBLE EVALUATION")
        print("=" * 70)

        # Predictions
        y_pred = self.ensemble.predict(X_test)
        y_proba = self.ensemble.predict_proba(X_test)[:, 1]

        # Metrics
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_proba)

        print(f"\nüìä Ensemble Performance:")
        print(f"  Test Accuracy:  {accuracy:.4f} ({accuracy * 100:.2f}%)")
        print(f"  Test Precision: {precision:.4f}")
        print(f"  Test Recall:    {recall:.4f}")
        print(f"  Test F1-Score:  {f1:.4f}")
        print(f"  Test AUC-ROC:   {auc:.4f}")

        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        print(f"\nüìà Confusion Matrix:")
        print(f"  TN: {cm[0, 0]:4d}  FP: {cm[0, 1]:4d}")
        print(f"  FN: {cm[1, 0]:4d}  TP: {cm[1, 1]:4d}")

        # Classification Report
        print(f"\nüìã Classification Report:")
        print(classification_report(y_test, y_pred, target_names=["DOWN", "UP"]))

        return {
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1": f1,
            "auc": auc,
        }

    def save_ensemble(self, output_dir="results/ensemble"):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Ensemble"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Save ensemble
        ensemble_file = output_path / "ensemble_model.pkl"
        joblib.dump(self.ensemble, ensemble_file)
        print(f"\nüíæ Ensemble saved: {ensemble_file}")

        # Save scaler
        scaler_file = output_path / "ensemble_scaler.pkl"
        joblib.dump(self.scaler, scaler_file)
        print(f"üíæ Scaler saved: {scaler_file}")

        # Save feature names
        if self.feature_names is not None:
            features_file = output_path / "feature_names.txt"
            with open(features_file, "w") as f:
                f.write("\n".join(self.feature_names))
            print(f"üíæ Feature names saved: {features_file}")

    def load_ensemble(self, input_dir="results/ensemble"):
        """‡πÇ‡∏´‡∏•‡∏î Ensemble"""
        input_path = Path(input_dir)

        # Load ensemble
        ensemble_file = input_path / "ensemble_model.pkl"
        self.ensemble = joblib.load(ensemble_file)
        print(f"‚úÖ Ensemble loaded: {ensemble_file}")

        # Load scaler
        scaler_file = input_path / "ensemble_scaler.pkl"
        self.scaler = joblib.load(scaler_file)
        print(f"‚úÖ Scaler loaded: {scaler_file}")

        return self.ensemble


def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    parser = argparse.ArgumentParser(description="Train Ensemble Model")
    parser.add_argument(
        "--data-path", "-d", required=True, help="Path to processed data CSV"
    )
    parser.add_argument(
        "--test-size", type=float, default=0.2, help="Test set size (default: 0.2)"
    )
    parser.add_argument(
        "--method",
        choices=["voting", "weighted"],
        default="voting",
        help="Ensemble method",
    )

    args = parser.parse_args()

    print("=" * 70)
    print("MODEL ENSEMBLE TRAINER")
    print("=" * 70)
    print(f"\nData: {args.data_path}")
    print(f"Test size: {args.test_size * 100}%")
    print(f"Method: {args.method}")

    # Load data
    print("\n" + "=" * 70)
    print("LOADING DATA")
    print("=" * 70)

    df = pd.read_csv(args.data_path)
    print(f"  Loaded {len(df)} rows, {len(df.columns)} columns")

    # Prepare features
    exclude_cols = [
        "target",
        "future_price",
        "time",
        "timestamp",
        "symbol",
        "timeframe",
    ]
    feature_cols = [col for col in df.columns if col not in exclude_cols]

    print(f"  Found {len(feature_cols)} features")

    # Handle missing values
    if df[feature_cols].isnull().any().any():
        print("  Warning: Found NaN, filling with 0")
        df[feature_cols] = df[feature_cols].fillna(0)

    # Check target distribution
    target_dist = df["target"].value_counts()
    print(f"  Target distribution:")
    for label, count in target_dist.items():
        label_name = "UP" if label == 1 else "DOWN"
        percentage = (count / len(df)) * 100
        print(f"    {label_name}: {count}/{len(df)} ({percentage:.1f}%)")

    # Split data
    print("\n" + "=" * 70)
    print("SPLITTING DATA")
    print("=" * 70)

    X = df[feature_cols].values
    y = df["target"].values

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=args.test_size, random_state=42, stratify=y
    )

    print(
        f"  Train: {len(X_train)} samples ({(y_train == 1).sum() / len(y_train) * 100:.1f}% UP)"
    )
    print(
        f"  Test:  {len(X_test)} samples ({(y_test == 1).sum() / len(y_test) * 100:.1f}% UP)"
    )

    # Scale features
    print("\n" + "=" * 70)
    print("SCALING FEATURES")
    print("=" * 70)

    ensemble = ModelEnsemble(ensemble_method=args.method)
    ensemble.feature_names = feature_cols

    X_train_scaled = ensemble.scaler.fit_transform(X_train)
    X_test_scaled = ensemble.scaler.transform(X_test)

    # Create and train individual models
    ensemble.create_models()

    # Split train into train+val for individual model evaluation
    X_tr, X_val, y_tr, y_val = train_test_split(
        X_train_scaled, y_train, test_size=0.2, random_state=42, stratify=y_train
    )

    individual_results = ensemble.train_individual_models(X_tr, y_tr, X_val, y_val)

    # Train ensemble
    ensemble.train_ensemble(X_train_scaled, y_train)

    # Evaluate ensemble
    ensemble_results = ensemble.evaluate_ensemble(X_test_scaled, y_test)

    # Compare with individual models
    print("\n" + "=" * 70)
    print("COMPARISON: ENSEMBLE vs INDIVIDUAL MODELS")
    print("=" * 70)

    print(f"\n{'Model':<20} {'Accuracy':<12} {'F1-Score':<12} {'AUC-ROC':<12}")
    print("-" * 70)

    for name, results in individual_results.items():
        print(
            f"{name.upper():<20} {results['accuracy']:<12.4f} {results['f1']:<12.4f} {results['auc']:<12.4f}"
        )

    print("-" * 70)
    print(
        f"{'ENSEMBLE':<20} {ensemble_results['accuracy']:<12.4f} {ensemble_results['f1']:<12.4f} {ensemble_results['auc']:<12.4f}"
    )
    print("=" * 70)

    # Save
    ensemble.save_ensemble()

    print("\n" + "=" * 70)
    print("‚úÖ TRAINING COMPLETE!")
    print("=" * 70)
    print(f"\nFinal Ensemble Accuracy: {ensemble_results['accuracy'] * 100:.2f}%")
    print(f"F1-Score: {ensemble_results['f1']:.4f}")
    print(f"AUC-ROC: {ensemble_results['auc']:.4f}")


if __name__ == "__main__":
    main()
