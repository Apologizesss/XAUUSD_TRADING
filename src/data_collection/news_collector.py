"""
News Data Collector
-------------------
‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏ï‡∏•‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô

Features:
- ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å NewsAPI
- ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥, ‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à, ‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå
- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏î‡πâ‡∏ß‡∏¢ TextBlob ‡πÅ‡∏•‡∏∞ Transformers
- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame
"""

import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional

import pandas as pd
import requests
from dotenv import load_dotenv

# NLP Libraries
from textblob import TextBlob

# Temporarily disable transformers import to speed up startup
# try:
#     from transformers import pipeline
#
#     TRANSFORMERS_AVAILABLE = True
# except ImportError:
#     TRANSFORMERS_AVAILABLE = False
#     print("‚ö†Ô∏è Warning: transformers not available. Using TextBlob only.")

TRANSFORMERS_AVAILABLE = False


class NewsCollector:
    """
    ‡∏î‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥
    """

    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize News Collector

        Args:
            api_key: NewsAPI key (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å .env)
        """
        load_dotenv()
        self.api_key = api_key or os.getenv("NEWS_API_KEY")

        if not self.api_key:
            print("‚ö†Ô∏è Warning: NEWS_API_KEY not found in .env file")
            print("üìå Get your free API key from: https://newsapi.org/")

        self.base_url = "https://newsapi.org/v2/everything"

        # Keywords ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥
        self.gold_keywords = [
            "gold",
            "XAUUSD",
            "gold price",
            "precious metals",
            "federal reserve",
            "inflation",
            "dollar index",
            "USD",
            "interest rates",
            "treasury",
            "central bank",
        ]

        # Initialize sentiment analyzer
        self.sentiment_analyzer = None
        # Temporarily disable FinBERT due to PyTorch version incompatibility
        # Use TextBlob instead (fast and reliable for now)
        print("üìä Using TextBlob for sentiment analysis")
        if False and TRANSFORMERS_AVAILABLE:
            try:
                print("ü§ñ Loading FinBERT sentiment model...")

                # Auto-detect GPU
                import torch

                if torch.cuda.is_available():
                    device = 0  # Use GPU
                    print(f"   üöÄ GPU detected: {torch.cuda.get_device_name(0)}")
                else:
                    device = -1  # Use CPU
                    print(f"   üíª Using CPU (GPU not available)")

                # ‡πÉ‡∏ä‡πâ FinBERT ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô
                # Use safetensors to avoid torch.load vulnerability
                os.environ["TRANSFORMERS_OFFLINE"] = "0"

                self.sentiment_analyzer = pipeline(
                    "sentiment-analysis",
                    model="ProsusAI/finbert",
                    device=device,
                    max_length=512,
                    truncation=True,
                    batch_size=8 if device == 0 else 4,  # Larger batch for GPU
                    use_safetensors=True,  # Force use safetensors format
                )

                device_name = "GPU" if device == 0 else "CPU"
                print(f"‚úÖ FinBERT model loaded successfully on {device_name}")
            except Exception as e:
                print(f"‚ö†Ô∏è Could not load FinBERT: {e}")
                print("üìå Using TextBlob as fallback")

    def fetch_news(
        self,
        query: str = "gold OR XAUUSD OR 'gold price'",
        from_date: Optional[datetime] = None,
        to_date: Optional[datetime] = None,
        language: str = "en",
        sort_by: str = "relevancy",
        page_size: int = 100,
    ) -> List[Dict]:
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å NewsAPI

        Args:
            query: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            from_date: ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (default: 7 ‡∏ß‡∏±‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á)
            to_date: ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î (default: ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ)
            language: ‡∏†‡∏≤‡∏©‡∏≤
            sort_by: ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° (relevancy, popularity, publishedAt)
            page_size: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î

        Returns:
            List of news articles
        """
        if not self.api_key:
            print("‚ùå Error: NEWS_API_KEY is required")
            return []

        # Set default dates
        if to_date is None:
            to_date = datetime.now()
        if from_date is None:
            from_date = to_date - timedelta(days=7)

        # Format dates
        from_str = from_date.strftime("%Y-%m-%d")
        to_str = to_date.strftime("%Y-%m-%d")

        # API parameters
        params = {
            "q": query,
            "from": from_str,
            "to": to_str,
            "language": language,
            "sortBy": sort_by,
            "pageSize": page_size,
            "apiKey": self.api_key,
        }

        try:
            print(f"\nüì∞ Fetching news from {from_str} to {to_str}...")
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()

            if data["status"] == "ok":
                articles = data.get("articles", [])
                print(f"‚úÖ Found {len(articles)} articles")
                return articles
            else:
                print(f"‚ùå API Error: {data.get('message', 'Unknown error')}")
                return []

        except requests.exceptions.RequestException as e:
            print(f"‚ùå Request Error: {e}")
            return []
        except Exception as e:
            print(f"‚ùå Error: {e}")
            return []

    def analyze_sentiment_textblob(self, text: str) -> Dict:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏î‡πâ‡∏ß‡∏¢ TextBlob

        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå

        Returns:
            Dict with sentiment scores
        """
        try:
            blob = TextBlob(text)
            polarity = blob.sentiment.polarity  # -1 to 1
            subjectivity = blob.sentiment.subjectivity  # 0 to 1

            # Convert to category
            if polarity > 0.1:
                sentiment = "positive"
            elif polarity < -0.1:
                sentiment = "negative"
            else:
                sentiment = "neutral"

            return {
                "sentiment": sentiment,
                "polarity": polarity,
                "subjectivity": subjectivity,
                "method": "textblob",
            }
        except Exception as e:
            print(f"‚ö†Ô∏è TextBlob error: {e}")
            return {
                "sentiment": "neutral",
                "polarity": 0.0,
                "subjectivity": 0.0,
                "method": "textblob",
            }

    def analyze_sentiment_finbert(self, text: str) -> Dict:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏î‡πâ‡∏ß‡∏¢ FinBERT

        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå

        Returns:
            Dict with sentiment scores
        """
        if not self.sentiment_analyzer:
            return self.analyze_sentiment_textblob(text)

        try:
            # Truncate text to 512 tokens (BERT limit)
            text = text[:512]

            result = self.sentiment_analyzer(text)[0]

            sentiment = result["label"].lower()
            score = result["score"]

            # Convert to polarity scale (-1 to 1)
            if sentiment == "positive":
                polarity = score
            elif sentiment == "negative":
                polarity = -score
            else:  # neutral
                polarity = 0.0

            return {
                "sentiment": sentiment,
                "polarity": polarity,
                "confidence": score,
                "method": "finbert",
            }
        except Exception as e:
            print(f"‚ö†Ô∏è FinBERT error: {e}")
            return self.analyze_sentiment_textblob(text)

    def analyze_sentiment(self, text: str, method: str = "auto") -> Dict:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å method ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)

        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
            method: 'auto', 'finbert', 'textblob'

        Returns:
            Dict with sentiment scores
        """
        if method == "finbert" or (method == "auto" and self.sentiment_analyzer):
            return self.analyze_sentiment_finbert(text)
        else:
            return self.analyze_sentiment_textblob(text)

    def process_articles(
        self, articles: List[Dict], sentiment_method: str = "auto"
    ) -> pd.DataFrame:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment

        Args:
            articles: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å API
            sentiment_method: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment

        Returns:
            DataFrame with processed news
        """
        processed_data = []

        print(f"\nüîç Processing {len(articles)} articles...")

        for i, article in enumerate(articles):
            try:
                # Extract data
                title = article.get("title", "")
                description = article.get("description", "")
                content = article.get("content", "")
                published_at = article.get("publishedAt", "")
                source = article.get("source", {}).get("name", "Unknown")
                url = article.get("url", "")

                # Combine text for sentiment analysis
                full_text = f"{title}. {description}"

                # Analyze sentiment
                sentiment_result = self.analyze_sentiment(full_text, sentiment_method)

                # Parse datetime
                try:
                    pub_datetime = pd.to_datetime(published_at)
                except:
                    pub_datetime = datetime.now()

                processed_data.append(
                    {
                        "timestamp": pub_datetime,
                        "title": title,
                        "description": description,
                        "source": source,
                        "url": url,
                        "sentiment": sentiment_result["sentiment"],
                        "polarity": sentiment_result["polarity"],
                        "confidence": sentiment_result.get("confidence", 0.0),
                        "subjectivity": sentiment_result.get("subjectivity", 0.0),
                        "method": sentiment_result["method"],
                    }
                )

                if (i + 1) % 10 == 0:
                    print(f"  Processed {i + 1}/{len(articles)} articles...")

            except Exception as e:
                print(f"‚ö†Ô∏è Error processing article {i}: {e}")
                continue

        df = pd.DataFrame(processed_data)

        if len(df) > 0:
            print(f"\n‚úÖ Successfully processed {len(df)} articles")
            print(f"\nüìä Sentiment Distribution:")
            print(df["sentiment"].value_counts())
            print(f"\nüìà Average Polarity: {df['polarity'].mean():.4f}")

        return df

    def get_gold_news(
        self, days: int = 7, sentiment_method: str = "auto"
    ) -> pd.DataFrame:
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment

        Args:
            days: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á
            sentiment_method: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment

        Returns:
            DataFrame with news and sentiment
        """
        to_date = datetime.now()
        from_date = to_date - timedelta(days=days)

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏ó‡∏≠‡∏á
        query = '("gold price" OR XAUUSD OR "gold trading" OR "gold market" OR "gold futures" OR "gold rally" OR "gold outlook" OR "precious metal" OR "federal reserve" OR "interest rate" OR "inflation" OR "dollar index") AND NOT (mining OR copper OR iron OR aluminum OR platinum OR palladium)'
        articles = self.fetch_news(query=query, from_date=from_date, to_date=to_date)

        if not articles:
            print("‚ö†Ô∏è No articles found")
            return pd.DataFrame()

        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        df = self.process_articles(articles, sentiment_method)

        return df

    def save_news(self, df: pd.DataFrame, output_dir: str = "data/news"):
        """
        ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß

        Args:
            df: DataFrame ‡∏Ç‡∏≠‡∏á‡∏Ç‡πà‡∏≤‡∏ß
            output_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        """
        if df.empty:
            print("‚ö†Ô∏è No data to save")
            return

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        filename = f"news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        filepath = output_path / filename

        df.to_csv(filepath, index=False)
        print(f"\nüíæ Saved news data to: {filepath}")
        print(f"   Total articles: {len(df)}")

        return filepath


def main():
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment
    """
    print("=" * 70)
    print("NEWS SENTIMENT COLLECTOR - GOLD TRADING")
    print("=" * 70)

    # Initialize collector
    collector = NewsCollector()

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß 7 ‡∏ß‡∏±‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á
    df_news = collector.get_gold_news(days=7)

    if not df_news.empty:
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        collector.save_news(df_news)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
        print("\n" + "=" * 70)
        print("üì∞ SAMPLE NEWS")
        print("=" * 70)
        print(df_news[["timestamp", "title", "sentiment", "polarity"]].head(10))

    print("\n" + "=" * 70)
    print("‚úÖ COLLECTION COMPLETE")
    print("=" * 70)


if __name__ == "__main__":
    main()
